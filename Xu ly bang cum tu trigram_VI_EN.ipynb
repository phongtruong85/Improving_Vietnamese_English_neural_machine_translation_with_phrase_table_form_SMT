{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Xu ly bang cum tu trigram_VI_EN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"HtYQkdkW_u_u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645456613811,"user_tz":-420,"elapsed":20456,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"e30f1bf3-f028-4f78-d795-e0b3ef984ace"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Code xử lý dữ liệu tháng 12.2021\n","\n","Phần 1: xử lý cụm từ và trích xuất được cặp cụm từ trigram vi-en dịch lẫn nhau.\n","Bước xử lý cho cụm từ vi-en\n","Bước 1: xử lý thô phrase-table vi-en\n","Bước 2: xử lý trích xuất cụm từ vi-en trong đó cụm vi là trigram.\n","Bước 3: xử lý trích xuất cụm từ vi-en trong đó có xác suất dịch là lớn nhất file bangcumtu-3gram-vi-en.txt\n","Thực hiện tương tự cho cụm từ en-vi ta được file bangcumtu-3gram-en-vi.txt\n","\n","Cuối cùng ta so sánh hai file bangcumtu-3gram-vi-en.txt và bangcumtu-3gram-en-vi.txt nếu cụm từ vi-en có ở cả 2 file trên thì nó chính là cụm từ cần tìm cuối cùng ( cụm từ dịch lẫn nhau)\n","\n","#############################\n","Xử lý bước 2 để loại bỏ bớt những cụm từ tiếng Việt bị lặp từ mà ý nghĩa không thay đổi trong cụm En, cụ thể nếu cụm dịch En là giống nhau thì ta chọn cụm nguồn Vi có chiều dài là dài nhất.\n"],"metadata":{"id":"4zxyTxDQ-0lP"}},{"cell_type":"code","metadata":{"id":"12xg2_uuRXn8"},"source":["# Cài đặt Tool Tokenize\n","#! pip install underthesea\n","#! pip install mosestokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_uAh_OXdx1ff","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645457796366,"user_tz":-420,"elapsed":336,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"1b6d8843-cfb0-40bd-e312-08338c3fe4cd"},"source":["# Cấu hình word tokenize\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize #tool tokenize tiếng anh\n","#from underthesea import word_tokenize # tool tokenize tiếng việt\n","#from mosestokenizer import *\n","import re\n","#import gzip"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ECqr9cWp-ej","executionInfo":{"status":"ok","timestamp":1645456757979,"user_tz":-420,"elapsed":346,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"d0a36e13-05b0-4908-a8e3-c0923c9907bc"},"source":["%cd '/content/drive/My Drive/'"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive\n"]}]},{"cell_type":"code","metadata":{"id":"fPGr-uGHQXMo","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1645023160314,"user_tz":-420,"elapsed":364,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"8772f445-b513-4668-a7b7-973b1133ec35"},"source":["# Khai báo đường dẫn file phrase-table, có 2 loại phrase-table là dịch tiếng Việt - tiếng Anh và ngược lại\n","# phrase-table vi-en\n","SOURCE_FILE = 'data/bangcumtu/phrase-table-trigram-vi-en'\n","TARGET_FILE = 'data/bangcumtu/phrase-table-trigram-vi-en-clean'\n","\n","'''\n","# phrase-table en-vi\n","SOURCE_FILE = 'data/train/phrase-table-en-vi'\n","TARGET_FILE = 'data/train/phrase-table-en-vi-clean.txt'\n","'''\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n# phrase-table en-vi\\nSOURCE_FILE = 'data/train/phrase-table-en-vi'\\nTARGET_FILE = 'data/train/phrase-table-en-vi-clean.txt'\\n\""]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"v1VU69KpQSsu"},"source":["# xóa những cụm từ chứa những ký tự đặc biệt {.:;,$&*?/\\|!+-]+}\n","# xử lý chung cho cụm vi và cụm en\n","\n","import re\n","with open(SOURCE_FILE,'r', encoding=\"utf8\") as file_1, open(TARGET_FILE,'a', encoding=\"utf8\") as file_2:\n","    for lines in file_1:\n","        line = lines.rstrip().split('|||')\n","        check1 = re.findall(r'[.:;,$%&*?/\\!+-]+', line[1])\n","        #check2 = re.findall('\\d', line[0])# kiểm tra cụm vn toàn số thì loại bỏ\n","        check2 = re.findall('\\d', line[1])# kiểm tra cụm vn nếu chứa toàn số thì loại bỏ\n","        check3 = re.findall(r'[.:;,$%&*?/\\!+-]+', line[0])\n","        #print(l_vi)\n","        if not check1 and not check2 and not check3: \n","            file_2.write(lines)\n","#print(random.sample(tmp_text,20))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-dCmSTaQzzA","executionInfo":{"status":"ok","timestamp":1640162211313,"user_tz":-420,"elapsed":12238,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"ff8b317f-326b-46c0-a6bb-d75bc2dac853"},"source":["#Count number lines\n","with open(SOURCE_FILE, 'r', encoding='utf8') as file1:\n","    Counter1 = 0\n","  \n","# Reading from file \n","    Content = file1.read() \n","    CoList = Content.split(\"\\n\") \n","  \n","    for i in CoList: \n","        if i: \n","            Counter1 += 1\n","file1.close()\n","         \n","\n","with open(TARGET_FILE, 'r', encoding='utf8') as file2:\n","    Counter2 = 0\n","  \n","# Reading from file \n","    Content = file2.read() \n","    CoList = Content.split(\"\\n\") \n","  \n","    for i in CoList: \n","        if i: \n","            Counter2 += 1\n","file2.close()\n","# Print results\n","print(\"This is the number of lines in the SOURCE_FILE: \",Counter1)\n","print(\"This is the number of lines in the TARGET_FILE: \",Counter2) "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This is the number of lines in the SOURCE_FILE:  6418963\n","This is the number of lines in the TARGET_FILE:  3518608\n"]}]},{"cell_type":"code","metadata":{"id":"Hzns0vdKvrdp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645456790835,"user_tz":-420,"elapsed":339,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"ade9b5ab-12b0-4898-8884-d3f79a3f74ef"},"source":["# Khai báo function Xử lý file phrase-table vi-en\n","#Xử lý rút ra được các cụm từ vi-en mà trong đó cụm vi là trigram\n","# xóa các cụm từ khuyết cụm en, bắt đầu bằng dấu \"!,.:?\\\"\"\n","\n","source_text = []\n","combine_text_vi_en = []\n","combine_raw = []\n","#vn_tokenize = MosesTokenizer('vi') # tokenize tiếng Việt\n","#en_tokenize = MosesTokenizer('en') # tokenize tiếng Anh\n","# Khởi tạo các hàm xử lý chuỗi\n","def InsertSpace(token):\n","    result = ''\n","    \n","    for text in token:\n","        result += text + ' '\n","    \n","    return result.rstrip()\n","'''\n","def normalizeString(s):\n","    s = html.unescape(s)\n","    # Seperate words and marks by adding spaces between them\n","    #marks = '[.!?,-${}()]'\n","    #r = \"([\"+\"\\\\\".join(marks)+\"])\"\n","    #s = re.sub(r, r\" \\1 \", s)\n","    # replace continuous spaces with a single space\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","'''\n","\n","# code xử lý cụm tiếng việt - tiếng anh\n","def FilterPairs_vi_en (l):\n","    # tokenzie word by nltk\n","    source_tokenize = word_tokenize(l[0])\n","    target_tokenize = word_tokenize(l[1])\n","    # tokenize with mosestokenizer\n","    #source_tokenize = vn_tokenize(l[0])\n","    #target_tokenize = en_tokenize(l[1])\n","    # Thêm space vào các token từ\n","    source_raw = InsertSpace(source_tokenize)\n","    target_raw = InsertSpace(target_tokenize)\n","         \n","    # Kiểm tra độ dài của cụm từ vi thỏa điều kiện\n","    if len(source_tokenize) == 3  and len(target_tokenize) >= 2 :\n","        combine_raw = source_raw + '|||' + target_raw + '|||' + l[2] #l[2] là các thông số xác suất dịch của bảng cụm từ\n","        #combine_text = source_raw + '\\t' + target_raw\n","        combine_text_vi_en.append(combine_raw)\n","        #print(combine_text[0])\n","    #l = combine_text\n","\n","    return combine_text_vi_en\n","\n","# Xử lý file nguồn\n","\n","print('Finish')\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Finish\n"]}]},{"cell_type":"code","source":["# Khai báo function Xử lý file phrase-table en-vi\n","#Xử lý rút ra được các cụm từ vi-en mà trong đó cụm vi là trigram\n","# xóa các cụm từ khuyết cụm en, bắt đầu bằng dấu \"!,.:?\\\"\"\n","\n","source_text = []\n","combine_text = []\n","combine_raw = []\n","vn_tokenize = MosesTokenizer('vi') # tokenize tiếng Việt\n","en_tokenize = MosesTokenizer('en') # tokenize tiếng Anh\n","# Khởi tạo các hàm xử lý chuỗi\n","def InsertSpace(token):\n","    result = ''\n","    \n","    for text in token:\n","        result += text + ' '\n","    \n","    return result.rstrip()\n","'''\n","def normalizeString(s):\n","    s = html.unescape(s)\n","    # Seperate words and marks by adding spaces between them\n","    #marks = '[.!?,-${}()]'\n","    #r = \"([\"+\"\\\\\".join(marks)+\"])\"\n","    #s = re.sub(r, r\" \\1 \", s)\n","    # replace continuous spaces with a single space\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","'''\n","# Code xử lý chuỗi tiếng Anh - tiếng Việt\n","\n","def FilterPairs (l):\n","    source_tokenize = en_tokenize(l[0]) # tokenize en\n","    target_tokenize = vn_tokenize(l[1]) # tokenize vi\n","    source_raw = InsertSpace(source_tokenize)\n","    target_raw = InsertSpace(target_tokenize)\n","    #combine_text = source_raw.rstrip() + '|||' + target_raw.rstrip()\n","    \n","\n","    \n","    # Kiểm tra độ dài của cụm từ vi thỏa điều kiện\n","    if len(source_tokenize) >= 2  and len(target_tokenize) == 3 :\n","        # Đảo cụm từ vi ra trước cụm từ en\n","        combine_raw = target_raw + '|||' + source_raw + '|||' + l[2]# đảo vị trí của cụm từ vi lên trước cụm từ en nhằm mục tiêu xác định dịch lẫn nhau ở bước tiếp theo\n","        #combine_text = source_raw + '\\t' + target_raw\n","        combine_text.append(combine_raw)\n","        #print(combine_text[0])\n","    #l = combine_text\n","\n","    return combine_text\n","\n","# Xử lý file nguồn\n","\n","print('Finish')\n"],"metadata":{"id":"SbTSBSLnQ6Qf"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmoMyBHylSkJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645009774815,"user_tz":-420,"elapsed":905055,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"73f2c3c4-e8a0-42c3-ea1a-81ffc75572b3"},"source":["# Code xử lý cụm từ để tạo trigram phrase-table vi-en\n","PHRASE_FILE_VI_EN = 'data/bangcumtu/phrase-table-vi-en'\n","PHRASE_TARGET_VI_EN = 'data/bangcumtu/phrase-table-trigram-vi-en'\n","import random\n","import numpy\n","#result_text = []\n","with open(PHRASE_FILE_VI_EN,'r', encoding=\"utf8\") as file1:\n","    for line in file1:\n","        lines = line.strip().split('|||')\n","        new_lines = FilterPairs_vi_en(lines) #    \n","\n","# Lưu các cụm từ 3 gram vào file\n","with open(PHRASE_TARGET_VI_EN,'w', encoding=\"utf8\") as file2:\n","    for item in combine_text_vi_en:\n","        #print('%s\\t' % item)\n","        file2.write(\"%s\\n\" % item)\n","\n","print('Finished')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished\n"]}]},{"cell_type":"code","source":["# Code xử lý cụm từ để tạo trigram phrase-table en-vi\n","PHRASE_FILE = 'data/train/phrase-table-en-vi-clean.txt'\n","PHRASE_TARGET = 'data/train/phrase-table-en-vi-3gram.txt'\n","import random\n","import numpy\n","#result_text = []\n","with open(PHRASE_FILE,'r', encoding=\"utf8\") as file1:\n","    for line in file1:\n","        lines = line.strip().split('|||')\n","        new_lines = FilterPairs(lines) #    \n","\n","# Lưu các cụm từ 3 gram vào file\n","with open(PHRASE_TARGET,'w', encoding=\"utf8\") as file2:\n","    for item in combine_text:\n","        #print('%s\\t' % item)\n","        file2.write(\"%s\\n\" % item)\n","\n","print('Finished')"],"metadata":{"id":"Z14fhP6TTjbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Gộp xác suất dịch phrase-table\n","# code này đang chạy trên spyder\n","# Khai báo phrase-table trigram vi-en\n","SOURCE_FILE_VI_EN = 'data/bangcumtu/phrase-table-trigram-vi-en-clean'\n","TARGET_FILE_VI_EN = 'data/bangcumtu/phrase-table-trigram-vi-en-clean-gop-p'\n","\n","# Khai báo phrase-table trigram en-vi\n","#SOURCE_FILE = 'data/train/phrase-3gram-en-vi.txt'\n","#TARGET_FILE = 'data/train/phrase-3gram-en-vi-gop-p.txt'\n","\n","# cụm từ dạng vi|||en||| 4 giá trí xác suất dịch : chiếc máy tính|||front of a single computer||| 0.2 8.90453e-11 1 0.000276122\n","\n","# xử lý gộp xác suất cho bảng cụm từ vi-en\n","with open(SOURCE_FILE_VI_EN,'r' , encoding=\"utf-8\") as file_1, open(TARGET_FILE_VI_EN,'w' , encoding=\"utf-8\") as file_2:\n","    for lines in file_1:\n","        l1 = lines.rstrip().split('|||')\n","        p3_l = ''.join(l1[2])\n","        #print(p3_l)\n","        p3_l1 = p3_l.rstrip().split(' ')\n","        #print('xác suất: ',p3_l1[0],'-',p3_l1[1],'-',p3_l1[2], '-',p3_l1[3], '-',p3_l1[4])\n","        num = float(p3_l1[1]) + float(p3_l1[2]) \n","        l = l1[0] + '|||' + l1[1] + '|||' + str(num) \n","        \n","        file_2.write('%s\\n'%l)\n","\n","'''\n","#Xử lý gộp xác suất cho bảng cụm từ en-vi\n","with open(SOURCE_FILE,'r' , encoding=\"utf-8\") as file_3, open(TARGET_FILE,'w' , encoding=\"utf-8\") as file_4:\n","    for lines in file_3:\n","        l1 = lines.rstrip().split('|||')\n","        p3_l = ''.join(l1[2])\n","        #print(p3_l)\n","        p3_l1 = p3_l.rstrip().split(' ')\n","        #print('xác suất: ',p3_l1[0],'-',p3_l1[1],'-',p3_l1[2], '-',p3_l1[3], '-',p3_l1[4])\n","        num = float(p3_l1[1]) + float(p3_l1[2]) \n","        l = l1[0] + '|||' + l1[1] + '|||' + str(num) \n","        \n","        file_4.write('%s\\n'%l)\n","'''\n","print('Finished')"],"metadata":{"id":"tU93q9iAU3ti","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645023390755,"user_tz":-420,"elapsed":7115,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"87ce53d5-56b6-4834-8a63-60a75b424872"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished\n"]}]},{"cell_type":"code","source":["# Chọn cụm từ có xác suất gộp lớn nhất cho bảng cụm từ vi-en\n","import operator\n","#from operator import itemgetter\n","# Lộc cụm từ vn-en với điều kiện xác suất gộp là lớn nhất\n","# sử dụng định dạng từ điển (dictionary) để lộc cụm en\n","#khai báo đường dẫn file\n","\n","# Tạo từ điển để tìm cụm en dựa trên điều kiện id là cụm vn '|||' xác suất\n","SOURCE_FILE = 'data/bangcumtu/phrase-table-trigram-vi-en-clean-gop-p'\n","# File chứa cụm vn và xác suất gộp lớn nhất\n","\n","# Kết quả\n","TARGET = 'data/bangcumtu/bangcumtu-3gram-vi-en.txt'\n","bangCumTu = {}\n","source_text = []\n","expectedBangCumTu = {}\n","with open(SOURCE_FILE,'r', encoding='utf-8') as f1:\n","    for line in f1:\n","        splitArray = line.split('|||')\n","        tupleValue = (splitArray[1], splitArray[2])\n","        bangCumTu[splitArray[0]] = tupleValue\n","       \n","for key, value in bangCumTu.items():\n","    if max(value, key = operator.itemgetter(1)):\n","        \n","        expectedBangCumTu[key] = value\n","    \n"," \n","#print('------------Finished-----------')       \n","'''\n","# ghi kết quả\n","'''\n","with open(TARGET, 'w', encoding='utf-8') as f2:\n","    for id in expectedBangCumTu:\n","        #Ghi output_dict vào file kết quả\n","        f2.write('{0}|||{1}\\n'.format(id, expectedBangCumTu[id][0]))\n","\n","print ('--------Finished---------')"],"metadata":{"id":"bIw6D9roYSLg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645025879018,"user_tz":-420,"elapsed":4445,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"c1ab4d59-73f6-430b-d2ed-e59e496d7b38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------Finished---------\n"]}]},{"cell_type":"code","source":["# Chọn cụm từ có xác suất gộp lớn nhất cho bảng cụm từ en-vi\n","import operator\n","#from operator import itemgetter\n","# Lộc cụm từ vn-en với điều kiện xác suất gộp là lớn nhất\n","# sử dụng định dạng từ điển (dictionary) để lộc cụm en\n","#khai báo đường dẫn file\n","\n","# Tạo từ điển để tìm cụm en dựa trên điều kiện id là cụm vn '\\t' xác suất\n","SOURCE_FILE = 'data/train/phrase-3gram-en-vi-gop-p.txt'\n","# File chứa cụm vn và xác suất gộp lớn nhất\n","#SOURCE = 'D:\\data_phrase_table/thang_11/test-3-en-gop.txt'\n","# Kết quả\n","TARGET = 'data/train/bangcumtu-3gram-en-vi.txt'\n","bangCumTu = {}\n","source_text = []\n","expectedBangCumTu = {}\n","with open(SOURCE_FILE,'r', encoding='utf-8') as f1:\n","    for line in f1:\n","        splitArray = line.split('|||')\n","        tupleValue = (splitArray[1], splitArray[2])\n","        bangCumTu[splitArray[0]] = tupleValue\n","       \n","for key, value in bangCumTu.items():\n","    if max(value, key = operator.itemgetter(1)):\n","        \n","        expectedBangCumTu[key] = value\n","    \n"," \n","#print('------------Finished-----------')       \n","'''\n","# ghi kết quả\n","'''\n","with open(TARGET, 'w', encoding='utf-8') as f2:\n","    for id in expectedBangCumTu:\n","        #Ghi output_dict vào file kết quả\n","        f2.write('{0}|||{1}\\n'.format(id, expectedBangCumTu[id][0]))\n","\n","print ('--------Finished---------')"],"metadata":{"id":"O5qOpgW-fZjd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sắp xếp lại file cụm từ theo alphabet\n","S_FILE = 'bangcumtu-3gram-en-vn.txt'\n","T_FILE = 'data/train/bangcumtu-3gram-en-vn-final.txt'\n","with open(S_FILE, 'r', encoding='utf8') as f1:\n","  with open(T_FILE, 'w', encoding='utf8') as f2:\n","      data=f1.readlines()\n","      data.sort()\n","      for i in range(len(data)):\n","          f2.write(f'{data[i]}')"],"metadata":{"id":"dKi21BN7ZVcF"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JlccHykdMTYW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640624338055,"user_tz":-420,"elapsed":3744,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"977cd477-863b-4c1b-bb38-fcf185f51bed"},"source":["# so sanh cum vi-en va en-vi de tim ra cum dich lan nhau\n","# BỎ NHỮNG LINE KHÔNG GIỐNG NHAU Ở 2 FILE từ đó suy ra được những line giống nhau ở cả hai phrase-table chính là cụm dịch lẫn nhau\n","from time import time\n","import random\n","start = time()\n","# Đường dẫn file\n","PHRASE_VI_EN = 'data/bangcumtu-3gram-vi-en.txt'\n","PHRASE_EN_VI = 'data/bangcumtu-3gram-en-vi.txt'\n","PHRASE_VI_EN_MUL = 'data/bangcumtu-3gram-vi-en-mul.txt'\n","\n","with open(PHRASE_VI_EN, 'r', encoding=\"utf8\") as file1:\n","    with open(PHRASE_EN_VI, 'r', encoding=\"utf8\") as file2:\n","        same = set(file1).intersection(file2)\n","  \n","print(\"Common Lines in Both Files\")\n","with open(PHRASE_VI_EN_MUL,'w', encoding=\"utf8\") as file3:  \n","  for line in same:\n","    file3.write(\"%s\" % line)\n","\n","file1.close()\n","file2.close()\n","file3.close()\n","print('Finished at:')\n","print('Time: ',time() - start)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Common Lines in Both Files\n","Finished at:\n","Time:  3.295499324798584\n"]}]},{"cell_type":"markdown","source":["Phần 2: Bước xử lý tìm kiếm và thay thế cụm vi thành cụm en trong tập câu song ngữ và lấy mẫu (sampling)"],"metadata":{"id":"B67kTG-0Zgfr"}},{"cell_type":"markdown","source":["Tìm cụm dịch vi-en trong cặp câu song ngữ của tập train data, tạo thêm data nếu thỏa điều kiện k ( k là số câu song ngữ chứa cặp phrase-table vi-en)\n","Đoạn code này vì phải xử lý hơn 400k cặp cụm từ vi-en, nên phải chia nhỏ mỗi bước chỉ chạy 100k cặp cụm từ, và chạy code trên Spyder (trên windows 10)"],"metadata":{"id":"e0Pzo_l3Zghg"}},{"cell_type":"code","source":["# code xử lý này được chạy trên Spyder, mỗi lần duyệt qua 100k cặp cụm từ vi-en\n","#Khai báo hàm tìm kiếm và thay thế cụm vi-en\n","def search_string_in_file(file_name, vn_1, en_1):\n","#Search for the given string in file and return lines containing that string,\n","#along with line numbers\n","    #line_number = 0\n","    #list_of_samples = []\n","    list_of_results = []\n","    # Open the file in read only mode\n","    with open(file_name, 'r', encoding=\"utf-8\") as read_obj:\n","      # Read all lines in the file one by one\n","      for line in read_obj:\n","        # For each line, check if line contains the string\n","          #line_number += 1 # index line numbers\n","          line_vn, line_en = line.lower().strip().split('|||')\n","          # kiểm tra điều kiện cụm vi trong câu train tiếng Việt và cụm en trong câu train tiếng Anh\n","          if vn_1.lower() in line_vn  and en_1.lower() in line_en :\n","                  # Thay cụm vi = cụm en trong câu tiếng Việt\n","                  line_raw = line_vn.replace(vn_1.lower(), en_1) +'|||' + line_en\n","                  \n","                  list_of_results.append(line_raw.rstrip())\n","                  # Sampling 20 lines and write to file data\n","                  #list_of_samples = random.sample(list_of_results)\n","                  #print(line_raw)\n","    read_obj.close()\n","    return list_of_results\n","#!/usr/bin/env python\n","start = time.time()\n","print(\"Begin\")\n","print(time.ctime())\n","# Khai bao duong dan file\n","# Khai báo data train cặp câu vi-en\n","DATA_TRAIN = 'train-clean-vi-en.txt'\n","# File chứa cụm từ trigram vi-en \n","# File cum tư vn-en có xác suất dịch lớn nhất chứa 450k cặp\n","PHRASE_FILE = '/data_phrase_table/thang12/bangcumtu-3gram-vn-en.txt'\n","# File chứa cặp câu vi-en thỏa điều kiện và thực hiện sampling\n","AUG_FILE = '/data_phrase_table/thang12/sampling-4gram-k5-250k-280k.txt'\n","# Lưu lại bảng cụm từ vi-en thỏa điều kiện\n","PHRASE_AUG = '/data_phrase_table/thang12/cum-tu-4gram-thoa-dk-k5-250k-280k.txt'\n","\n","# Xử lý tìm kiếm cụm từ vi-en\n","\n","with open(PHRASE_FILE,'r' , encoding=\"utf-8\") as file_1:\n","    lines = file_1.readlines()\n","    list_phrase_pairs = []\n","    list_of_samples = [] \n","    \n","    for line_1 in lines[:100000]: # mỗi lần chạy 100k cụm từ\n","         vi_first_comb, en_first_comb = line_1.lower().split('|||')\n","         vi_first_comb, en_first_comb = vi_first_comb.strip(), en_first_comb.strip() # loại dấu cách \n","         vi_first_comb , en_first_comb = vi_first_comb +' ', en_first_comb + ' '\n","         #vi_str1, en_str1 = line_1.strip().split('\\t')\n","         #vi_str1, en_str1 = vi_str1.strip(), en_str1.strip()\n","         list_results = search_string_in_file(DATA_TRAIN, vi_first_comb, en_first_comb)\n","         \n","       \n","         # Sampling với hệ số k là số câu thỏa điều kiện\n","         # với k = 5 tức là số cặp câu thỏa điều kiện chứa cụm từ vi-en là lớn hơn 5 câu\n","         if len(list_results) >= 5 :\n","             #Sampling results\n","             results = random.sample(list_results, 5)\n","                        \n","             with open(AUG_FILE, 'a', encoding='utf-8') as file_2:\n","                 \n","                 for elem in results:\n","                     file_2.write('%s\\n' % elem)\n","            \n","             # Write cụm từ\n","             with open(PHRASE_AUG, 'a', encoding='utf-8') as file_3:\n","                 \n","                 file_3.write('%s' % line_1)\n","                     \n","                     \n","        \n","file_2.close()\n","file_1.close()\n","#print('Total Matched lines : ', num_list)\n","\n","print('Finished')\n","print(time.ctime())\n","end = time.time()\n","print(end - start)# Tìm và thay thế cụm từ trong file train data\n","             "],"metadata":{"id":"xHcgEJlKZY_6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gộp file data tăng cường sau khi thay thế cụm vi-en vào trong file data train ban đầu"],"metadata":{"id":"wg_9YVNgqj5H"}},{"cell_type":"code","source":["import glob\n","# ghép all file.txt trong thư mục AUG_Sample_10 thành file train data mới\n","#Copy toàn bộ file data tìm được ở bước 2 và data train ban đầu vào folder /content/drive/My Drive/data/AUG_Sample_5\n","%cd '/content/drive/My Drive/data/AUG_Sample_5'\n","read_files = glob.glob(\"/content/drive/My Drive/data/AUG_Sample_5/*.txt\")\n","\n","with open(\"result.txt\", \"wb\") as outfile:\n","    for f in read_files:\n","        with open(f, \"rb\") as infile:\n","            outfile.write(infile.read())"],"metadata":{"id":"BVzeQsGYqjj5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Phần 3: tạo data train cho fairseq"],"metadata":{"id":"o_BZRfpXr_QX"}},{"cell_type":"code","source":["source_file = \"/content/drive/My Drive/data/AUG_Sample_5/result.txt\"\n","train_vi = \"/content/drive/My Drive/NMT2/data/ntrain.vi\"\n","train_en = \"/content/drive/My Drive/NMT2/data/ntrain.en\"\n","\n","list_vi = []\n","list_en = []\n","\n","with open(source_file,'r', encoding=\"utf8\") as file:\n","    for line in file:   \n","        l = line.strip().split(\"|||\")\n","        list_vi.append(l[0])\n","        list_en.append(l[1])\n","# write to file\n","with open(train_vi, 'w', encoding='utf8') as file:\n","    for item in list_vi:\n","        file.write(\"%s\\n\" % item)\n","with open(train_en, 'w', encoding='utf8') as file:\n","    for item in list_en:\n","        file.write(\"%s\\n\" % item)"],"metadata":{"id":"CAW0kBp6ru2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Xử lý bước 2 để tạo cụm dịch 1-1 VI-EN"],"metadata":{"id":"mh2R5UcH37xK"}},{"cell_type":"code","source":[""],"metadata":{"id":"R5S3tZIO4Wq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk import tokenize\n","# Tạo từ điển để tìm cụm en dựa trên điều kiện id là cụm vn '\\t' xác suất\n","SOURCE = 'data/bangcumtu/bangcumtu-3gram-vi-en.txt'\n","# File chứa cụm vn và xác suất gộp lớn nhất\n","#SOURCE = 'D:\\data_phrase_table/thang_11/test-3-en-gop.txt'\n","# Kết quả\n","TARGET = 'data/bangcumtu/bangcumtu-3gram-vi-en-can-tim.txt'\n","bangCumTu = {}\n","source_text = []\n","\n","with open(SOURCE,'r', encoding='utf-8') as f1:\n","    for line in f1:\n","      l = line.replace('_',' ')\n","      new_l = l.rstrip().split('|||')\n","      id = ''.join(new_l[1]) # cụm En\n","      value = ''.join(new_l[0]) # cụm Vi\n","      if id not in bangCumTu or len(word_tokenize(value))>len(word_tokenize(bangCumTu[id][0])):\n","          bangCumTu[id] = value\n","    \n"," \n","#print('------------Finished-----------')       \n","'''\n","# ghi kết quả\n","'''\n","with open(TARGET, 'w', encoding='utf-8') as f2:\n","    for id in bangCumTu:\n","        #Ghi output_dict vào file kết quả\n","        f2.write('{0}|||{1}\\n'.format(bangCumTu[id], id))\n","\n","print('--------Finished---------')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWFZP0UW37Fj","executionInfo":{"status":"ok","timestamp":1645458064386,"user_tz":-420,"elapsed":50368,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}},"outputId":"be9242bd-e48a-47b5-98d2-7934c08e2dbb"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--------Finished---------\n"]}]},{"cell_type":"code","source":["# Sắp xếp lại file cụm từ theo alphabet\n","S_FILE = 'data/bangcumtu/bangcumtu-3gram-vi-en-can-tim.txt'\n","T_FILE = 'data/bangcumtu/bangcumtu-3gram-vi-en-can-tim-sort.txt'\n","with open(S_FILE, 'r', encoding='utf8') as f1:\n","  with open(T_FILE, 'w', encoding='utf8') as f2:\n","      data=f1.readlines()\n","      data.sort()\n","      for i in range(len(data)):\n","          f2.write(f'{data[i]}')"],"metadata":{"id":"ChXx7Sd28dab","executionInfo":{"status":"ok","timestamp":1645458110200,"user_tz":-420,"elapsed":899,"user":{"displayName":"Văn Phong Trương","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07220257246981086629"}}},"execution_count":13,"outputs":[]}]}